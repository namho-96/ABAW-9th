import os
import sys
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from PIL import Image
from tqdm import tqdm
import gc
import multiprocessing as mp
import argparse
from concurrent.futures import ThreadPoolExecutor
import time
from pathlib import Path

# -------------------------------------------------------------------
# Configuration and Optimizations
# -------------------------------------------------------------------

# CUDA ìµœì í™” ì„¤ì •
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

# ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ì „ì—­ ì„¤ì •
BATCH_SIZE = 8  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
MAX_WORKERS_PER_GPU = 2  # GPUë‹¹ ì›Œì»¤ ìˆ˜ ì¦ê°€
PREFETCH_BUFFER_SIZE = 16  # ì´ë¯¸ì§€ í”„ë¦¬í˜ì¹˜ ë²„í¼ í¬ê¸°

# -------------------------------------------------------------------
# Utility Functions
# -------------------------------------------------------------------

def uniform_sample_range(start, end, num=4):
    """ì£¼ì–´ì§„ ë²”ìœ„ ë‚´ì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§í•  ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return np.linspace(start, end, num=num, dtype=int)

def clean_caption(text):
    """ìƒì„±ëœ ìº¡ì…˜ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    joined = " ".join(lines)
    if joined and joined[-1] not in {'.', '!', '?'}:
        joined += '.'
    return joined

def preload_images_batch(frame_paths):
    """ì´ë¯¸ì§€ë“¤ì„ ë°°ì¹˜ë¡œ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    images = []
    valid_paths = []
    
    def load_single_image(path):
        try:
            return Image.open(path).convert("RGB")
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {path}: {e}")
            return None
    
    # ThreadPoolExecutorë¡œ ì´ë¯¸ì§€ ë¡œë”© ë³‘ë ¬í™”
    with ThreadPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(load_single_image, frame_paths))
    
    for img, path in zip(results, frame_paths):
        if img is not None:
            images.append(img)
            valid_paths.append(path)
    
    return images, valid_paths

# -------------------------------------------------------------------
# Optimized Captioning Core Function
# -------------------------------------------------------------------

def extract_captions_for_frames_optimized(chat, frame_dir, out_dir):
    """ë°°ì¹˜ ì²˜ë¦¬ì™€ ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¡œ ìº¡ì…˜ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    os.makedirs(out_dir, exist_ok=True)
    video_name = os.path.basename(frame_dir)
    
    try:
        frame_files = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])
    except FileNotFoundError:
        print(f"ğŸš¨ [PID:{os.getpid()}] í”„ë ˆì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {frame_dir}")
        return

    n_frames = len(frame_files)
    if n_frames < 4:
        return

    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ì²˜ë¦¬ë¥¼ ë°°ì¹˜ë¡œ ìµœì í™”
    for seg_idx, seg_start in enumerate(range(0, n_frames, 64)):
        seg_end = min(seg_start + 64, n_frames)
        if seg_end - seg_start < 4:
            continue
        
        frame_indices_to_process = uniform_sample_range(seg_start, seg_end - 1, 4)
        frame_paths = [os.path.join(frame_dir, frame_files[f_idx]) for f_idx in frame_indices_to_process]
        
        # ë°°ì¹˜ë¡œ ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¡œë“œ
        images, valid_paths = preload_images_batch(frame_paths)
        
        if not images:
            continue
            
        seg_captions = []
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”
        for i in range(0, len(images), BATCH_SIZE):
            batch_images = images[i:i + BATCH_SIZE]
            batch_paths = valid_paths[i:i + BATCH_SIZE]
            
            batch_captions = process_image_batch(chat, batch_images, batch_paths)
            seg_captions.extend(batch_captions)
            
            # ë°°ì¹˜ ì²˜ë¦¬ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            del batch_images
            torch.cuda.empty_cache()
        
        # ë‚¨ì€ ì´ë¯¸ì§€ë“¤ ì •ë¦¬
        for img in images:
            del img
        del images
        
        # ê²°ê³¼ ì €ì¥
        out_file = os.path.join(out_dir, f"{video_name}_seg{seg_idx:03d}.txt")
        with open(out_file, 'w', encoding='utf-8') as f_out:
            f_out.write("\n".join(seg_captions))

def process_image_batch(chat, images, paths):
    """ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    from minigpt4.conversation.conversation import CONV_VISION_Vicuna0
    
    captions = []
    prompt = (
        "Describe the facial expression in this image using valence and arousal dimensions. "
        "Indicate whether the valence (positive or negative emotion) and arousal (calm or excited) are high, medium, or low. "
        "Explain briefly why you think so."
    )
    
    for img, path in zip(images, paths):
        try:
            # ëŒ€í™” ìƒíƒœ ì¬ì‚¬ìš© ìµœì í™”
            chat_state = CONV_VISION_Vicuna0.copy()
            img_list = []
            
            # ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì¸ì½”ë”©
            chat.upload_img(img, chat_state, img_list)
            chat.encode_img(img_list)
            
            chat.ask(prompt, chat_state)
            
            # ì¶”ë¡  íŒŒë¼ë¯¸í„° ìµœì í™” - do_sample íŒŒë¼ë¯¸í„° ì œê±°
            llm_message = chat.answer(
                conv=chat_state, 
                img_list=img_list, 
                num_beams=1,  # beam search ì¤„ì—¬ì„œ ì†ë„ í–¥ìƒ
                temperature=0.7,
                max_new_tokens=30, 
                max_length=500
                # do_sample=False íŒŒë¼ë¯¸í„° ì œê±° - ì´ íŒŒë¼ë¯¸í„°ê°€ ì˜¤ë¥˜ì˜ ì›ì¸
            )[0]
            
            captions.append(clean_caption(llm_message))
            
            # ì¦‰ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
            del chat_state, img_list
            
        except Exception as e:
            print(f"âš ï¸ [PID:{os.getpid()}] í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨ {os.path.basename(path)}: {e}")
            captions.append("Error generating caption for this frame.")
    
    return captions

# -------------------------------------------------------------------
# Enhanced Multiprocessing Worker
# -------------------------------------------------------------------

def dedicated_worker_optimized(gpu_id, task_queue, done_queue, cfg_path):
    """
    ìµœì í™”ëœ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ - ëª¨ë¸ ë¡œë”© ìµœì í™” ë° ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 
    """
    from transformers import StoppingCriteriaList
    from minigpt4.common.config import Config
    from minigpt4.common.registry import registry
    from minigpt4.conversation.conversation import Chat, StoppingCriteriaSub
    from minigpt4 import models
    from minigpt4 import processors

    chat = None
    try:
        print(f"[Worker on GPU:{gpu_id}] ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        sys.stdout.flush()
        
        # GPU ì„¤ì • ìµœì í™”
        torch.cuda.set_device(gpu_id)
        
        args = argparse.Namespace(cfg_path=cfg_path, gpu_id=gpu_id, options=[])
        cfg = Config(args)
        model_config = cfg.model_cfg
        model_config.device_8bit = args.gpu_id
        
        # ëª¨ë¸ ë¡œë”© ì‹œ ë©”ëª¨ë¦¬ ìµœì í™”
        with torch.cuda.device(gpu_id):
            model_cls = registry.get_model_class(model_config.arch)
            model = model_cls.from_config(model_config).to(f'cuda:{gpu_id}')
            
            # ëª¨ë¸ì„ evaluation ëª¨ë“œë¡œ ì„¤ì •í•˜ì—¬ dropout ë“± ë¹„í™œì„±í™”
            model.eval()
            
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ëª¨ë¸ì„ half precisionìœ¼ë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
            # model = model.half()  # ì •í™•ë„ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜
            
        vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train
        vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)
        
        stop_words_ids = [torch.tensor(ids).to(f'cuda:{gpu_id}') for ids in [[835], [2277, 29937]]]
        stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])
        chat = Chat(model, vis_processor, device=f'cuda:{gpu_id}', stopping_criteria=stopping_criteria)
        
        print(f"[Worker on GPU:{gpu_id}] ì´ˆê¸°í™” ì™„ë£Œ. ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        sys.stdout.flush()

    except Exception as e:
        print(f"ğŸš¨ [Worker on GPU:{gpu_id}] ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", file=sys.stderr)
        while True:
            task = task_queue.get()
            if task == 'STOP': break
            done_queue.put('init_failed_task')
        return

    # ì„±ëŠ¥ í†µê³„ë¥¼ ìœ„í•œ ë³€ìˆ˜
    processed_count = 0
    start_time = time.time()
    
    while True:
        task = task_queue.get()
        if task == 'STOP':
            break
        
        frame_dir, out_dir = task
        task_start_time = time.time()
        
        try:
            extract_captions_for_frames_optimized(chat, frame_dir, out_dir)
            processed_count += 1
            task_duration = time.time() - task_start_time
            
            if processed_count % 10 == 0:  # 10ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
                avg_time = (time.time() - start_time) / processed_count
                print(f"[GPU:{gpu_id}] ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ, í‰ê·  ì‹œê°„: {avg_time:.2f}ì´ˆ/ë¹„ë””ì˜¤")
                
        except Exception as e:
            print(f"ğŸš¨ [Worker on GPU:{gpu_id}] ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (í´ë”: {os.path.basename(frame_dir)}): {e}", file=sys.stderr)
        finally:
            done_queue.put(frame_dir)
            
            # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
            if processed_count % 5 == 0:
                gc.collect()
                torch.cuda.empty_cache()

# -------------------------------------------------------------------
# Optimized Parallel Processing Orchestrator
# -------------------------------------------------------------------

def process_dataset_parallel_optimized(dataset_config, cfg_path, num_workers):
    """
    ìµœì í™”ëœ ë³‘ë ¬ ì²˜ë¦¬ - ì‘ì—… ë¶„ë°° ë° ë¡œë“œ ë°¸ëŸ°ì‹± ê°œì„ 
    """
    d_type = dataset_config['type']
    frame_root_dir = dataset_config['frame_dir']
    anno_root_dir = dataset_config['anno_dir']
    list_file_path = dataset_config['list_file']
    out_dir = dataset_config['out_dir']
    
    os.makedirs(out_dir, exist_ok=True)
    all_video_basenames = []
    dataset_name = "Unknown"

    print("-" * 50)
    if d_type == 'test':
        dataset_name = f"Test Set ({os.path.basename(list_file_path)})"
        print(f"ğŸ“ {dataset_name} ì²˜ë¦¬ ì‹œì‘...")
        try:
            with open(list_file_path, 'r') as f:
                all_video_basenames = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"ğŸš¨ğŸš¨ Test set ëª©ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {list_file_path}")
            return
    else:
        dataset_name = os.path.basename(anno_root_dir)
        print(f"ğŸ“ Annotation ê¸°ë°˜ ì²˜ë¦¬ ì‹œì‘ ({dataset_name})...")
        try:
            all_anno_files = sorted([f for f in os.listdir(anno_root_dir) if f.lower().endswith('.txt')])
            all_video_basenames = [os.path.splitext(f)[0] for f in all_anno_files]
        except FileNotFoundError:
            print(f"ğŸš¨ğŸš¨ ì–´ë…¸í…Œì´ì…˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {anno_root_dir}")
            return
            
    # ì´ë¯¸ ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ í™•ì¸ ìµœì í™”
    processed_videos = set()
    if os.path.exists(out_dir):
        existing_files = os.listdir(out_dir)
        processed_videos = {f.split('_seg')[0] for f in existing_files if f.endswith('.txt')}

    basenames_to_process = [b for b in all_video_basenames if b not in processed_videos]

    if not basenames_to_process:
        print(f"âœ… [{dataset_name}] ì²˜ë¦¬í•  ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"  - ì´ ë¹„ë””ì˜¤ ìˆ˜: {len(all_video_basenames)}ê°œ")
    print(f"  - ìƒˆë¡œ ì²˜ë¦¬í•  ë¹„ë””ì˜¤: {len(basenames_to_process)}ê°œ")

    # í í¬ê¸° ìµœì í™”
    task_queue = mp.Queue(maxsize=num_workers * 4)  # í í¬ê¸° ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ
    done_queue = mp.Queue()

    # ìœ íš¨í•œ ì‘ì—…ë“¤ì„ ë¯¸ë¦¬ í•„í„°ë§í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
    valid_tasks = []
    for video_name in basenames_to_process:
        frame_dir = os.path.join(frame_root_dir, video_name)
        if os.path.isdir(frame_dir):
            # í”„ë ˆì„ ìˆ˜ ë¯¸ë¦¬ í™•ì¸í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì‘ì—… ì œê±°
            try:
                frame_count = len([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])
                if frame_count >= 4:
                    valid_tasks.append((frame_dir, out_dir))
            except:
                continue
        else:
            print(f"âš ï¸ í”„ë ˆì„ í´ë” ëˆ„ë½, ê±´ë„ˆëœë‹ˆë‹¤: {frame_dir}")

    if not valid_tasks:
        print(f"âœ… ì²˜ë¦¬í•  ìœ íš¨í•œ ë¹„ë””ì˜¤ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"  - ì‹¤ì œ ì²˜ë¦¬í•  ìœ íš¨í•œ ë¹„ë””ì˜¤: {len(valid_tasks)}ê°œ")

    # ì‘ì—…ì„ íì— ì¶”ê°€ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì§„í–‰í•˜ì—¬ ë¸”ë¡œí‚¹ ë°©ì§€)
    def add_tasks_to_queue():
        for task in valid_tasks:
            task_queue.put(task)
        for _ in range(num_workers):
            task_queue.put('STOP')

    task_thread = ThreadPoolExecutor(max_workers=1)
    task_future = task_thread.submit(add_tasks_to_queue)

    # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    processes = []
    for i in range(num_workers):
        gpu_id = i % torch.cuda.device_count()  # GPU ìˆœí™˜ í• ë‹¹
        p = mp.Process(target=dedicated_worker_optimized, args=(gpu_id, task_queue, done_queue, cfg_path))
        p.start()
        processes.append(p)

    # ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ (ë” ìƒì„¸í•œ ì •ë³´ ì œê³µ)
    start_time = time.time()
    completed_tasks = 0
    
    for _ in tqdm(range(len(valid_tasks)), desc=f"Processing {dataset_name}"):
        result = done_queue.get()
        completed_tasks += 1
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        if completed_tasks % 50 == 0:
            elapsed_time = time.time() - start_time
            avg_time_per_task = elapsed_time / completed_tasks
            remaining_tasks = len(valid_tasks) - completed_tasks
            estimated_remaining_time = remaining_tasks * avg_time_per_task
            
            print(f"\nğŸ“Š ì§„í–‰ ìƒí™©: {completed_tasks}/{len(valid_tasks)} "
                  f"(í‰ê·  {avg_time_per_task:.2f}ì´ˆ/ë¹„ë””ì˜¤, "
                  f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time/60:.1f}ë¶„)")

    # ì •ë¦¬ ì‘ì—…
    task_future.result()  # ì‘ì—… ì¶”ê°€ ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    task_thread.shutdown()
    
    for p in processes:
        p.join()
    
    total_time = time.time() - start_time
    print(f"âœ… {dataset_name} ì²˜ë¦¬ ì™„ë£Œ: {len(valid_tasks)}ê°œ ë¹„ë””ì˜¤, ì´ ì‹œê°„: {total_time/60:.1f}ë¶„")

# -------------------------------------------------------------------
# Main Execution Section
# -------------------------------------------------------------------

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜. ì„¤ì •ì„ ì •ì˜í•˜ê³  ë°ì´í„°ì…‹ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
    """
    CFG_PATH = "eval_configs/minigpt4_eval.yaml"
    
    try:
        num_gpus = torch.cuda.device_count()
        if num_gpus == 0:
            print("ğŸš¨ GPUê°€ ì—†ìŠµë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        print(f"ğŸš€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜: {num_gpus}ê°œ")
        
        # GPUë‹¹ ì›Œì»¤ ìˆ˜ ì¦ê°€ë¡œ ì²˜ë¦¬ëŸ‰ í–¥ìƒ
        num_workers = num_gpus * MAX_WORKERS_PER_GPU
        print(f"ğŸ”§ ì´ ì›Œì»¤ ìˆ˜: {num_workers}ê°œ (GPUë‹¹ {MAX_WORKERS_PER_GPU}ê°œ)")
        
    except Exception as e:
        print(f"ğŸš¨ GPU í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›Œì»¤ ìˆ˜ë¥¼ 1ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        num_workers = 1

    # --- ì²˜ë¦¬í•  ë°ì´í„°ì…‹ ëª©ë¡ ì •ì˜ ---
    datasets = [
        {
            'type': 'test',
            'frame_dir': '../../../dataset/affectnet/new_frames',
            'anno_dir': None,
            'out_dir': '../../../dataset/affectnet/text/test',
            'list_file': '../../../dataset/affectnet/names_of_videos_in_each_test_set/Valence_Arousal_Estimation_Challenge_test_set_release.txt'
        }
    ]

    overall_start_time = time.time()
    
    for d_config in datasets:
        dataset_start_time = time.time()
        process_dataset_parallel_optimized(d_config, CFG_PATH, num_workers)
        
        dataset_duration = time.time() - dataset_start_time
        print(f"â±ï¸ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œê°„: {dataset_duration/60:.1f}ë¶„")
        
        # ë°ì´í„°ì…‹ ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            # ëª¨ë“  GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            for i in range(torch.cuda.device_count()):
                with torch.cuda.device(i):
                    torch.cuda.empty_cache()

    total_duration = time.time() - overall_start_time
    print(f'ğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì†Œìš” ì‹œê°„: {total_duration/60:.1f}ë¶„')

if __name__ == '__main__':
    try:
        mp.set_start_method('spawn', force=True)
        print("âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹ì„ 'spawn'ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    except RuntimeError:
        print("â“˜ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹ì´ ì´ë¯¸ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # í”„ë¡œì„¸ìŠ¤ ìš°ì„ ìˆœìœ„ ì„¤ì • (Linuxì—ì„œ)
    try:
        import psutil
        p = psutil.Process()
        p.nice(-10)  # ë†’ì€ ìš°ì„ ìˆœìœ„ ì„¤ì •
        print("âœ… í”„ë¡œì„¸ìŠ¤ ìš°ì„ ìˆœìœ„ë¥¼ ë†’ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    except:
        pass
    
    main()