import os
import sys
import numpy as np
import pandas as pd
import gc
import cv2
from tqdm import tqdm
import multiprocessing as mp

import jax
import jax.numpy as jnp
import tensorflow as tf

# 'videoprism' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
from videoprism import models as vp

# -------------------------------------------------------------------
# Configuration Section
# -------------------------------------------------------------------
mp.set_start_method('spawn', force=True)
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'
tf.config.set_visible_devices([], 'GPU')
jax.config.update('jax_enable_x64', False)


def init_model(model_name='videoprism_public_v1_base'):
    """JAX ëª¨ë¸ê³¼ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global flax_model, loaded_state
    flax_model = vp.MODELS[model_name]()
    loaded_state = vp.load_pretrained_weights(model_name)


@jax.jit
def forward_fn(inputs, train=False):
    """JIT ì»´íŒŒì¼ëœ JAX ëª¨ë¸ì˜ forward pass í•¨ìˆ˜"""
    return flax_model.apply(loaded_state, inputs, train=train)

# -------------------------------------------------------------------
# Frame Processing Functions
# -------------------------------------------------------------------

def read_image_files(frame_paths: list, target_size: tuple=(288, 288)) -> np.ndarray | None:
    """ì£¼ì–´ì§„ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì½ì–´ numpy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    frames = []
    for path in frame_paths:
        try:
            frame = cv2.imread(path)
            if frame is None:
                print(f'âš ï¸ í”„ë ˆì„ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (íŒŒì¼ì´ ì—†ê±°ë‚˜ ì†ìƒë¨): {path}')
                continue
            
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, target_size)
            frame = frame.astype(np.float32) / 255.0
            frames.append(frame)
        except Exception as e:
            print(f"ğŸš¨ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {path}, ì˜¤ë¥˜: {e}")
            continue

    if not frames:
        return None
        
    return np.array(frames)


def extract_features_from_frames(
    frame_dir: str, 
    out_dir: str, 
    anno_path: str | None,
    num_samples: int = 16, 
    window_size: int = 64, 
    frame_size: int = 288
):
    """
    í´ë”ì— ìˆëŠ” ì‹¤ì œ í”„ë ˆì„ ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ í”¼ì²˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    anno_pathê°€ ì£¼ì–´ì§€ë©´(Train/Validation) ë¼ë²¨ì„ í•¨ê»˜ ì²˜ë¦¬í•˜ê³ , Noneì´ë©´(Test) í”¼ì²˜ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    is_test_set = (anno_path is None)
    label_df = None

    if not is_test_set:
        try:
            label_df = pd.read_csv(anno_path)
        except FileNotFoundError:
            print(f"ğŸš¨ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {anno_path}")
            return
        except Exception as e:
            print(f"ğŸš¨ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {anno_path}, {e}")
            return

    os.makedirs(out_dir, exist_ok=True)
    video_name = os.path.basename(frame_dir)

    try:
        frame_files = sorted([f for f in os.listdir(frame_dir) if f.lower().endswith('.jpg')])
        n_frames = len(frame_files)
    except FileNotFoundError:
        print(f"ğŸš¨ í”„ë ˆì„ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {frame_dir}")
        return

    if n_frames < window_size:
        print(f"âš ï¸ ì „ì²´ í”„ë ˆì„ ìˆ˜ê°€ {window_size}ê°œ ë¯¸ë§Œì´ë¯€ë¡œ ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {video_name}")
        return

    for seg_idx, start_list_idx in enumerate(range(0, n_frames, window_size)):
        end_list_idx = start_list_idx + window_size
        
        if end_list_idx > n_frames:
            continue

        segment_frame_files = frame_files[start_list_idx:end_list_idx]
        frame_paths_to_read = []
        final_label = None

        if is_test_set:
            all_segment_paths = [os.path.join(frame_dir, f) for f in segment_frame_files]
            picker_indices = np.linspace(0, len(all_segment_paths) - 1, num=num_samples, dtype=int)
            frame_paths_to_read = [all_segment_paths[i] for i in picker_indices]
        else:
            valid_frame_paths = []
            invalid_frame_paths = []
            for filename in segment_frame_files:
                try:
                    frame_number = int(os.path.splitext(filename)[0])
                    label = label_df.iloc[frame_number - 1]
                    frame_path = os.path.join(frame_dir, filename)
                    
                    if label['valence'] != -5:
                        valid_frame_paths.append(frame_path)
                    else:
                        invalid_frame_paths.append(frame_path)
                except (ValueError, IndexError):
                    print(f"âš ï¸ ë¼ë²¨ ì¡°íšŒ ì‹¤íŒ¨ (íŒŒì¼ëª…: {filename}), ì´ í”„ë ˆì„ì€ ë¬´ì‹œë©ë‹ˆë‹¤.")
                    continue
            
            if len(valid_frame_paths) >= num_samples:
                num_valid = len(valid_frame_paths)
                picker_indices = np.linspace(0, num_valid - 1, num=num_samples, dtype=int)
                frame_paths_to_read = [valid_frame_paths[i] for i in picker_indices]

                total_valence, total_arousal = 0, 0
                for path in frame_paths_to_read:
                    frame_number = int(os.path.splitext(os.path.basename(path))[0])
                    label = label_df.iloc[frame_number - 1]
                    total_valence += label['valence']
                    total_arousal += label['arousal']
                final_label = np.array([total_valence / num_samples, total_arousal / num_samples])
            else:
                all_segment_paths = valid_frame_paths + invalid_frame_paths
                if not all_segment_paths: continue
                num_total = len(all_segment_paths)
                picker_indices = np.linspace(0, num_total - 1, num=min(num_samples, num_total), dtype=int)
                frame_paths_to_read = [all_segment_paths[i] for i in picker_indices]
                final_label = np.array([-5.0, -5.0])

        if not frame_paths_to_read:
            continue

        frames = read_image_files(frame_paths_to_read, target_size=(frame_size, frame_size))
        
        if frames is None:
            print(f'ì„¸ê·¸ë¨¼íŠ¸ {seg_idx} ì²˜ë¦¬ ì‹¤íŒ¨ (ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨): {video_name}')
            continue

        inputs = jnp.asarray(frames[None, ...])
        embeddings, _ = forward_fn(inputs)
        feat_np = np.asarray(embeddings)
        
        filepath = os.path.join(out_dir, f"{video_name}_seg{seg_idx:03d}.npz")
        
        if is_test_set:
            np.savez_compressed(filepath, feature=feat_np)
        else:
            np.savez_compressed(filepath, feature=feat_np, label=final_label)

# -------------------------------------------------------------------
# Multiprocessing Section
# -------------------------------------------------------------------

def dedicated_worker(gpu_id: int, task_queue: mp.Queue, done_queue: mp.Queue, worker_args: dict):
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    init_model()
    print(f"[Worker on GPU:{gpu_id}] ì´ˆê¸°í™” ì™„ë£Œ. ì‘ì—… ì‹œì‘.")
    sys.stdout.flush()

    for args in iter(task_queue.get, 'STOP'):
        frame_folder_path, anno_root_dir, output_dir = args
        video_name = os.path.basename(frame_folder_path)
        
        anno_path = None
        if anno_root_dir:
            anno_path = os.path.join(anno_root_dir, f"{video_name}.txt")
        
        extract_features_from_frames(
            frame_dir=frame_folder_path,
            out_dir=output_dir,
            anno_path=anno_path,
            num_samples=worker_args['num_samples'],
            window_size=worker_args['window_size'],
            frame_size=worker_args['frame_size']
        )
        done_queue.put(video_name)

# -------------------------------------------------------------------
# Parallel Processing Setup
# -------------------------------------------------------------------

def process_dataset_parallel(
    frame_root_dir: str, 
    output_dir: str, 
    anno_root_dir: str | None,
    num_samples: int = 16, 
    window_size: int = 64, 
    frame_size: int = 288, 
    num_workers: int = 4,
    is_test_set: bool = False,
    list_file_path: str | None = None # â˜…â˜…â˜… Test set ëª©ë¡ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
):
    """ë°ì´í„°ì…‹ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    os.makedirs(output_dir, exist_ok=True)
    
    all_video_basenames = []
    dataset_name = "Unknown"

    # â˜…â˜…â˜… Test setì˜ ê²½ìš°, ëª©ë¡ íŒŒì¼ì—ì„œ ë¹„ë””ì˜¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜¤ë„ë¡ ìˆ˜ì • â˜…â˜…â˜…
    if is_test_set:
        if not list_file_path:
            print("ğŸš¨ Test Set ì²˜ë¦¬ë¥¼ ìœ„í•´ 'list_file_path' ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        dataset_name = f"Test_Set_from_file"
        print(f"ğŸ“ {dataset_name} ì²˜ë¦¬ ì‹œì‘ (ëª©ë¡ íŒŒì¼: {os.path.basename(list_file_path)})...")
        try:
            with open(list_file_path, 'r') as f:
                # íŒŒì¼ì˜ ê° ì¤„ì„ ì½ì–´ ê³µë°±ì„ ì œê±°í•˜ê³ , ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                all_video_basenames = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"ğŸš¨ğŸš¨ Test set ëª©ë¡ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {list_file_path}")
            return
    else: # Train/Validation Set
        if not anno_root_dir:
            print("ğŸš¨ Train/Validation Set ì²˜ë¦¬ë¥¼ ìœ„í•´ 'anno_root_dir' ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        dataset_name = os.path.basename(anno_root_dir)
        print(f"ğŸ“ Annotation-based ì²˜ë¦¬ ì‹œì‘ ({dataset_name})...")
        try:
            all_anno_files = sorted([f for f in os.listdir(anno_root_dir) if f.lower().endswith('.txt')])
            all_video_basenames = [os.path.splitext(f)[0] for f in all_anno_files]
        except FileNotFoundError:
            print(f"ğŸš¨ğŸš¨ ì–´ë…¸í…Œì´ì…˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {anno_root_dir}")
            return

    processed_video_basenames = set()
    if os.path.exists(output_dir):
        for f_name in os.listdir(output_dir):
            if f_name.endswith('.npz'):
                processed_video_basenames.add(f_name.split('_seg')[0])

    basenames_to_process = [basename for basename in all_video_basenames if basename not in processed_video_basenames]

    if not basenames_to_process:
        print(f"âœ… [{dataset_name}] ì²˜ë¦¬í•  ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"  - ì´ ë¹„ë””ì˜¤ ìˆ˜: {len(all_video_basenames)}ê°œ")
    print(f"  - ìƒˆë¡œ ì²˜ë¦¬í•  ë¹„ë””ì˜¤: {len(basenames_to_process)}ê°œ")

    try:
        num_available_gpus = jax.device_count()
        if num_workers > num_available_gpus:
            print(f"ê²½ê³ : ì›Œì»¤ ìˆ˜({num_workers})ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜({num_available_gpus})ë³´ë‹¤ ë§ìŠµë‹ˆë‹¤. {num_available_gpus}ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
            num_workers = num_available_gpus
    except Exception as e:
        print(f"JAX GPU ê°ì§€ ì‹¤íŒ¨: {e}. ì„¤ì •ëœ num_workers({num_workers})ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    task_queue = mp.Queue()
    done_queue = mp.Queue()
    
    tasks_added = 0
    for basename in basenames_to_process:
        frame_folder_path = os.path.join(frame_root_dir, basename)
        
        if not os.path.isdir(frame_folder_path):
            print(f"âš ï¸ í”„ë ˆì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {frame_folder_path}")
            continue

        args = (frame_folder_path, anno_root_dir if not is_test_set else None, output_dir)
        task_queue.put(args)
        tasks_added += 1

    for _ in range(num_workers):
        task_queue.put('STOP')

    if tasks_added == 0:
        print(f"âœ… ì²˜ë¦¬í•  ë¹„ë””ì˜¤ ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ í´ë”ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        return

    worker_args = {'num_samples': num_samples, 'window_size': window_size, 'frame_size': frame_size}
    processes = []
    for i in range(num_workers):
        p = mp.Process(target=dedicated_worker, args=(i, task_queue, done_queue, worker_args))
        processes.append(p)
        p.start()

    for _ in tqdm(range(tasks_added), desc=f'Processing {dataset_name}', unit='video'):
        done_queue.get()
        
    for p in processes:
        p.join()

# -------------------------------------------------------------------
# Main Execution Section
# -------------------------------------------------------------------

def main():
    print(f'JAX Platform: {jax.lib.xla_bridge.get_backend().platform}, OpenCV Version: {cv2.__version__}')

    datasets = [
        {
            'type': 'train',
            'frame_dir': '../../../dataset/affectnet/new_frames',
            'anno_dir': '../../../dataset/affectnet/9th ABAW Annotations/VA_Estimation_Challenge/Train_Set',
            'out_dir': '../../../dataset/affectnet/features_new/train/video',
            'list_file': None # Train setì€ ì‚¬ìš© ì•ˆí•¨
        },
        {
            'type': 'validation',
            'frame_dir': '../../../dataset/affectnet/new_frames',
            'anno_dir': '../../../dataset/affectnet/9th ABAW Annotations/VA_Estimation_Challenge/Validation_Set',
            'out_dir': '../../../dataset/affectnet/features_new/valid/video',
            'list_file': None # Validation setì€ ì‚¬ìš© ì•ˆí•¨
        },
        # â˜…â˜…â˜… Test setì— ëª©ë¡ íŒŒì¼ ê²½ë¡œ ì§€ì • â˜…â˜…â˜…
        {
            'type': 'test',
            'frame_dir': '../../../dataset/affectnet/new_frames', # Test set í”„ë ˆì„ë“¤ì´ ìˆëŠ” ìƒìœ„ í´ë”
            'anno_dir': None, 
            'out_dir': '../../../dataset/affectnet/features_new/test/video',
            'list_file': '../../../dataset/affectnet/names_of_videos_in_each_test_set/Valence_Arousal_Estimation_Challenge_test_set_release.txt' # Test set ë¹„ë””ì˜¤ ì´ë¦„ ëª©ë¡ íŒŒì¼
        }
    ]
    
    for d in datasets:
        print("-" * 50)
        is_test = (d['type'] == 'test')
        
        process_dataset_parallel(
            frame_root_dir=d['frame_dir'], 
            anno_root_dir=d['anno_dir'], 
            output_dir=d['out_dir'],
            num_samples=16,
            window_size=64,
            num_workers=4,
            is_test_set=is_test,
            list_file_path=d['list_file'] # Test set ëª©ë¡ íŒŒì¼ ê²½ë¡œ ì „ë‹¬
        )
        gc.collect()
        
    print('ğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')


if __name__ == '__main__':
    main()