import os
import sys
import numpy as np
import pandas as pd
import gc
import cv2
from tqdm import tqdm
import multiprocessing as mp

import jax
import jax.numpy as jnp
import tensorflow as tf

from videoprism import models as vp

# -------------------------------------------------------------------
# Configuration Section (ê¸°ì¡´ê³¼ ë™ì¼)
# -------------------------------------------------------------------
mp.set_start_method('spawn', force=True)
os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'
tf.config.set_visible_devices([], 'GPU')
jax.config.update('jax_enable_x64', False)

def configure_gpu_memory():
    try:
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        pass

def init_model(model_name='videoprism_public_v1_base'):
    global flax_model, loaded_state
    flax_model = vp.MODELS[model_name]()
    loaded_state = vp.load_pretrained_weights(model_name)

@jax.jit
def forward_fn(inputs, train=False):
    return flax_model.apply(loaded_state, inputs, train=train)

# -------------------------------------------------------------------
# Video/Frame Processing Functions (í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš©ìœ¼ë¡œ ìˆ˜ì •ë¨)
# -------------------------------------------------------------------

def get_video_info(video_path: str):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"ğŸš¨ [íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨] ë‹¤ìŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None, None, None
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    return total_frames, fps, (width, height)

def read_frames_at_indices(video_path: str, frame_indices: list, target_size: tuple=(288,288)) -> np.ndarray:
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f'ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}')
        return None
    frames = []
    for idx in sorted(frame_indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            print(f'í”„ë ˆì„ {idx} ì½ê¸° ì‹¤íŒ¨')
            break
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, target_size)
        frame = frame.astype(np.float32) / 255.0
        frames.append(frame)
    cap.release()
    if len(frames) != len(frame_indices):
        print(f'ìš”ì²­ {len(frame_indices)}ê°œ í”„ë ˆì„ ì¤‘ {len(frames)}ê°œë§Œ ì½ìŒ')
        return None
    return np.array(frames)

def process_video_segments(video_path: str, num_samples: int=16, window_size: int=64, frame_size: int=288):
    total_frames, _, _ = get_video_info(video_path)
    if total_frames is None or total_frames < window_size:
        return []

    results = []
    for start in range(0, total_frames, window_size):
        if start + window_size > total_frames:
            continue

        end = start + window_size - 1
        indices = np.linspace(start, end, num_samples, dtype=int)
        frames = read_frames_at_indices(video_path, indices.tolist(), target_size=(frame_size, frame_size))

        if frames is None:
            continue

        inputs = jnp.asarray(frames[None, ...])
        embeddings, _ = forward_fn(inputs)
        feat_np = np.asarray(embeddings)
        results.append({'feature': feat_np})

    return results

def extract_features_single_video(video_path: str, out_dir: str, num_samples: int=16, window_size: int=64, frame_size: int=288):
    os.makedirs(out_dir, exist_ok=True)
    name = os.path.splitext(os.path.basename(video_path))[0]
    # <<< ë³€ê²½ì : anno_path ì—†ì´ í•¨ìˆ˜ í˜¸ì¶œ >>>
    segments = process_video_segments(video_path, num_samples, window_size, frame_size)
    for idx, seg in enumerate(segments):
        filepath = os.path.join(out_dir, f"{name}_seg{idx:03d}.npz")
        # <<< ë³€ê²½ì : featureë§Œ ì €ì¥ >>>
        np.savez_compressed(filepath, feature=seg['feature'])

# -------------------------------------------------------------------
# Multiprocessing Section (í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš©ìœ¼ë¡œ ìˆ˜ì •ë¨)
# -------------------------------------------------------------------

def dedicated_worker(gpu_id: int, task_queue: mp.Queue, done_queue: mp.Queue, worker_args: dict):
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    init_model()
    print(f"[Worker on GPU:{gpu_id}] ì´ˆê¸°í™” ì™„ë£Œ. ì‘ì—… ì‹œì‘.")
    sys.stdout.flush()

    # <<< ë³€ê²½ì : task_queueì—ì„œ anno_dirë¥¼ ë°›ì§€ ì•ŠìŒ >>>
    for args in iter(task_queue.get, 'STOP'):
        video_path, output_dir = args
        
        # <<< ë³€ê²½ì : a_path (ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ) ìƒì„± ë¡œì§ ì œê±° >>>
        base = os.path.splitext(os.path.basename(video_path))[0]

        extract_features_single_video(
            video_path, output_dir, # <<< ë³€ê²½ì : a_path ì¸ì ì œê±°
            num_samples=worker_args['num_samples'],
            window_size=worker_args['window_size'],
            frame_size=worker_args['frame_size']
        )
        done_queue.put(base)

# -------------------------------------------------------------------
# Parallel Processing Setup (í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš©ìœ¼ë¡œ ìˆ˜ì •ë¨)
# -------------------------------------------------------------------

def process_dataset_parallel(input_dir: str, output_dir: str, num_samples: int=16, window_size: int=64, frame_size: int=288, num_workers: int=4):
    os.makedirs(output_dir, exist_ok=True)
    
    all_vids_in_dir = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(('.mp4', '.avi', '.mov'))])
    
    processed_video_basenames = set()
    if os.path.exists(output_dir):
        for f_name in os.listdir(output_dir):
            if f_name.endswith('.npz'):
                base_name = f_name.split('_seg')[0]
                processed_video_basenames.add(base_name)

    vids_to_process = []
    for video_filename in all_vids_in_dir:
        video_basename = os.path.splitext(video_filename)[0]
        if video_basename not in processed_video_basenames:
            vids_to_process.append(video_filename)

    if not vids_to_process:
        print(f"âœ… [{os.path.basename(input_dir)}] ì²˜ë¦¬í•  ìƒˆë¡œìš´ ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {len(all_vids_in_dir)}ê°œ ë¹„ë””ì˜¤ ëª¨ë‘ ì²˜ë¦¬ ì™„ë£Œ)")
        return
        
    print(f"ğŸ“ ë””ë ‰í† ë¦¬: {os.path.basename(input_dir)}")
    print(f"  - ì´ ë¹„ë””ì˜¤: {len(all_vids_in_dir)}ê°œ")
    print(f"  - ì´ë¯¸ ì²˜ë¦¬ëœ ë¹„ë””ì˜¤: {len(processed_video_basenames)}ê°œ")
    print(f"  - ìƒˆë¡œ ì²˜ë¦¬í•  ë¹„ë””ì˜¤: {len(vids_to_process)}ê°œ")

    try:
        num_available_gpus = jax.device_count()
        if num_workers > num_available_gpus:
            print(f"ê²½ê³ : ì›Œì»¤ ìˆ˜({num_workers})ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜({num_available_gpus})ë³´ë‹¤ ë§ìŠµë‹ˆë‹¤. ì›Œì»¤ ìˆ˜ë¥¼ {num_available_gpus}ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
            num_workers = num_available_gpus
    except Exception as e:
        print(f"JAXì—ì„œ GPU ì¥ì¹˜ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}. ì„¤ì •ëœ num_workers({num_workers})ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    task_queue = mp.Queue()
    done_queue = mp.Queue()

    # <<< ë³€ê²½ì : task íì— video ê²½ë¡œì™€ output ê²½ë¡œë§Œ ë„£ìŒ >>>
    for v in vids_to_process:
        args = (os.path.join(input_dir, v), output_dir)
        task_queue.put(args)

    for _ in range(num_workers):
        task_queue.put('STOP')

    worker_args = {
        'num_samples': num_samples,
        'window_size': window_size,
        'frame_size': frame_size
    }

    processes = []
    for i in range(num_workers):
        p = mp.Process(target=dedicated_worker, args=(i, task_queue, done_queue, worker_args))
        processes.append(p)
        p.start()

    for _ in tqdm(range(len(vids_to_process)), desc=f'Processing {os.path.basename(input_dir)}', unit='video'):
        done_queue.get()
        
    for p in processes:
        p.join()

# -------------------------------------------------------------------
# Main Execution Section (í…ŒìŠ¤íŠ¸ ë°ì´í„°ìš©ìœ¼ë¡œ ìˆ˜ì •ë¨)
# -------------------------------------------------------------------

def main():
    print(f'JAX Platform: {jax.lib.xla_bridge.get_backend().platform}, OpenCV Version: {cv2.__version__}')

    # <<< ë³€ê²½ì : í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì…ë ¥ ë¹„ë””ì˜¤ í´ë”, ì¶œë ¥ í”¼ì²˜ í´ë”) >>>
    test_datasets = [
        ('../../../dataset/dvd/DVD_Competition/Testing/converted_videos',
         '../../../dataset/dvd/DVD_Competition/Testing/features'),
        # ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€
        # ('/path/to/your/test_videos_2', '/path/to/your/features_2'),
    ]
    
    # <<< ë³€ê²½ì : anno_dir ì—†ì´ í•¨ìˆ˜ í˜¸ì¶œ >>>
    for inp, out in test_datasets:
        process_dataset_parallel(inp, out, num_workers=4)
        gc.collect()
        
    print('ğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')


if __name__ == '__main__':
    main()
    